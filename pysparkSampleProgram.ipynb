{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14187284\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext()\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#', 1), ('Apache', 1), ('Spark', 15), ('is', 7), ('unified', 1), ('analytics', 1), ('engine', 2), ('It', 2), ('provides', 1), ('high-level', 1), ('APIs', 1), ('in', 6), ('Scala,', 1), ('Java,', 1), ('an', 4), ('optimized', 1), ('supports', 2), ('computation', 1), ('analysis.', 1), ('set', 2), ('of', 5), ('tools', 1), ('SQL', 2), ('MLlib', 1), ('machine', 1), ('learning,', 1), ('GraphX', 1), ('graph', 1), ('processing,', 1), ('Structured', 1), ('<https://spark.apache.org/>', 1), ('Build](https://img.shields.io/appveyor/ci/ApacheSoftwareFoundation/spark/master.svg?style=plastic&logo=appveyor)](https://ci.appveyor.com/project/ApacheSoftwareFoundation/spark)', 1), ('Coverage](https://img.shields.io/badge/dynamic/xml.svg?label=pyspark%20coverage&url=https%3A%2F%2Fspark-test.github.io%2Fpyspark-coverage-site&query=%2Fhtml%2Fbody%2Fdiv%5B1%5D%2Fdiv%2Fh1%2Fspan&colorB=brightgreen&style=plastic)](https://spark-test.github.io/pyspark-coverage-site)', 1), ('Documentation', 1), ('latest', 1), ('programming', 1), ('guide,', 1), ('[project', 1), ('page](https://spark.apache.org/documentation.html).', 1), ('README', 1), ('only', 1), ('basic', 1), ('instructions.', 1), ('Building', 1), ('using', 5), ('[Apache', 1), ('run:', 1), ('do', 2), ('this', 1), ('downloaded', 1), ('more', 1), ('than', 1), ('-T', 1), ('Maven', 1), ('3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).', 1), ('documentation', 3), ('project', 1), ('site,', 1), ('at', 2), ('Spark\"](https://spark.apache.org/docs/latest/building-spark.html).', 1), ('development', 1), ('tips,', 1), ('developing', 1), ('IDE,', 1), ('[\"Useful', 1), ('Developer', 1), ('Interactive', 2), ('Shell', 2), ('The', 1), ('way', 1), ('start', 1), ('Try', 1), ('following', 2), ('scala>', 1), ('spark.range(1000', 2), ('*', 4), ('1000).count()', 2), ('Python', 2), ('Alternatively,', 1), ('use', 3), ('And', 1), ('run', 7), ('Example', 1), ('several', 1), ('programs', 2), ('them,', 1), ('`./bin/run-example', 1), ('[params]`.', 1), ('example:', 1), ('./bin/run-example', 2), ('SparkPi', 2), ('variable', 1), ('when', 1), ('examples', 2), ('spark://', 1), ('URL,', 1), ('YARN,', 1), ('\"local\"', 1), ('locally', 2), ('N', 1), ('abbreviated', 1), ('class', 2), ('name', 1), ('package.', 1), ('instance:', 1), ('print', 1), ('usage', 1), ('help', 1), ('no', 1), ('params', 1), ('are', 1), ('Testing', 1), ('Spark](#building-spark).', 1), ('Once', 1), ('built,', 1), ('tests', 2), ('using:', 1), ('./dev/run-tests', 1), ('Please', 4), ('guidance', 2), ('module,', 1), ('individual', 1), ('integration', 1), ('test,', 1), ('Note', 1), ('About', 1), ('uses', 1), ('library', 1), ('HDFS', 1), ('other', 1), ('Hadoop-supported', 1), ('storage', 1), ('systems.', 1), ('Because', 1), ('have', 1), ('changed', 1), ('different', 1), ('versions', 1), ('Hadoop,', 2), ('must', 1), ('against', 1), ('version', 1), ('refer', 2), ('YARN\"](https://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)', 1), ('particular', 2), ('distribution', 1), ('Hive', 2), ('Thriftserver', 1), ('distributions.', 1), ('[Configuration', 1), ('online', 1), ('overview', 1), ('configure', 1), ('Spark.', 1), ('Contributing', 1), ('guide](https://spark.apache.org/contributing.html)', 1), ('started', 1), ('contributing', 1), ('project.', 1), ('a', 9), ('for', 12), ('large-scale', 1), ('data', 2), ('processing.', 2), ('Python,', 2), ('and', 9), ('R,', 1), ('that', 2), ('general', 2), ('graphs', 1), ('also', 5), ('rich', 1), ('higher-level', 1), ('including', 4), ('DataFrames,', 1), ('Streaming', 1), ('stream', 1), ('[![Jenkins', 1), ('Build](https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7/badge/icon)](https://amplab.cs.berkeley.edu/jenkins/job/spark-master-test-sbt-hadoop-2.7)', 1), ('[![AppVeyor', 1), ('[![PySpark', 1), ('##', 9), ('Online', 1), ('You', 4), ('can', 7), ('find', 1), ('the', 24), ('documentation,', 1), ('on', 7), ('web', 1), ('This', 2), ('file', 1), ('contains', 1), ('setup', 1), ('built', 1), ('Maven](https://maven.apache.org/).', 1), ('To', 2), ('build', 4), ('its', 1), ('example', 3), ('programs,', 1), ('./build/mvn', 1), ('-DskipTests', 1), ('clean', 1), ('package', 1), ('(You', 1), ('not', 1), ('need', 1), ('to', 16), ('if', 4), ('you', 4), ('pre-built', 1), ('package.)', 1), ('one', 3), ('thread', 1), ('by', 1), ('option', 1), ('with', 4), ('Maven,', 1), ('see', 4), ('[\"Parallel', 1), ('builds', 1), ('More', 1), ('detailed', 2), ('available', 1), ('from', 1), ('[\"Building', 1), ('For', 3), ('info', 1), ('Tools\"](https://spark.apache.org/developer-tools.html).', 1), ('Scala', 2), ('easiest', 1), ('through', 1), ('shell:', 2), ('./bin/spark-shell', 1), ('command,', 2), ('which', 2), ('should', 2), ('return', 2), ('1,000,000,000:', 2), ('1000', 2), ('prefer', 1), ('./bin/pyspark', 1), ('>>>', 1), ('Programs', 1), ('comes', 1), ('sample', 1), ('`examples`', 2), ('directory.', 1), ('<class>', 1), ('will', 1), ('Pi', 1), ('locally.', 1), ('MASTER', 1), ('environment', 1), ('running', 1), ('submit', 1), ('cluster.', 1), ('be', 2), ('mesos://', 1), ('or', 3), ('\"yarn\"', 1), ('thread,', 1), ('\"local[N]\"', 1), ('threads.', 1), ('MASTER=spark://host:7077', 1), ('Many', 1), ('given.', 1), ('Running', 1), ('Tests', 1), ('first', 1), ('requires', 1), ('[building', 1), ('how', 3), ('[run', 1), ('tests](https://spark.apache.org/developer-tools.html#individual-tests).', 1), ('There', 1), ('Kubernetes', 1), ('resource-managers/kubernetes/integration-tests/README.md', 1), ('A', 1), ('Hadoop', 3), ('Versions', 1), ('core', 1), ('talk', 1), ('protocols', 1), ('same', 1), ('your', 1), ('cluster', 1), ('runs.', 1), ('[\"Specifying', 1), ('Version', 1), ('Enabling', 1), ('building', 2), ('Configuration', 1), ('Guide](https://spark.apache.org/docs/latest/configuration.html)', 1), ('review', 1), ('[Contribution', 1), ('information', 1), ('get', 1)]\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import os\n",
    "import py4j\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME')\n",
    "sc = SparkContext().getOrCreate()\n",
    "\n",
    "text_file = sc.textFile(spark_home + \"/README.md\")\n",
    "word_counts = text_file.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "print(word_counts.collect())\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
